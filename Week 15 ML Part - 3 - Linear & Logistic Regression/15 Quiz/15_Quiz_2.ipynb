{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: **Regression Quiz - 2**\n",
    "\n",
    "---\n",
    "\n",
    "### 1.  \n",
    "**What is R-squared?**\n",
    "\n",
    "- ✅ **A measure of how well a linear regression model fits the data**  \n",
    "- A measure of how well a logistic regression model fits the data  \n",
    "- A measure of how well a decision tree model fits the data  \n",
    "- A measure of how well a neural network model fits the data  \n",
    "\n",
    "**Explanation:** R-squared, or the coefficient of determination, indicates the proportion of variance in the dependent variable explained by the independent variable(s).\n",
    "\n",
    "---\n",
    "\n",
    "### 2.  \n",
    "**What is the range of R-squared values?**\n",
    "\n",
    "- ✅ **0 to 1**  \n",
    "- -1 to 1  \n",
    "- -∞ to ∞  \n",
    "- None of the above  \n",
    "\n",
    "**Explanation:** R-squared ranges from 0 (no explanatory power) to 1 (perfect explanation of variance).\n",
    "\n",
    "---\n",
    "\n",
    "### 3.  \n",
    "**What is RMSE?**\n",
    "\n",
    "- ✅ **Root Mean Squared Error**  \n",
    "- Relative Mean Squared Error  \n",
    "- Regularized Mean Squared Error  \n",
    "- Random Mean Squared Error  \n",
    "\n",
    "**Explanation:** RMSE measures the average magnitude of prediction errors. It is a common metric in regression analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.  \n",
    "**What is the formula for RMSE?**\n",
    "\n",
    "- ✅ **$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{pred},i} - y_{\\text{actual},i})^2}$**  \n",
    "\n",
    "- $\\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{pred},i} - y_{\\text{actual},i})^2$  \n",
    "\n",
    "- $\\sqrt{\\sum (y_{\\text{pred}} - y_{\\text{actual}}) / n}$  \n",
    "\n",
    "- $\\sum (y_{\\text{pred}} - y_{\\text{actual}}) / n$  \n",
    "\n",
    "**Explanation:** RMSE is the square root of the average squared difference between predicted and actual values.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.  \n",
    "**What is the formula for MSE?**\n",
    "\n",
    "- $\\text{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{pred},i} - y_{\\text{actual},i})^2}$  \n",
    "\n",
    "- ✅ **$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{pred},i} - y_{\\text{actual},i})^2$**  \n",
    "\n",
    "- $\\text{MSE} = \\sqrt{\\sum (y_{\\text{pred}} - y_{\\text{actual}}) / n}$  \n",
    "\n",
    "- $\\text{MSE} = \\sum (y_{\\text{pred}} - y_{\\text{actual}}) / n$  \n",
    "\n",
    "**Explanation:** MSE calculates the average of the squared differences between predicted and actual values.\n",
    "\n",
    "---\n",
    "\n",
    "### 6.  \n",
    "**Which type of regularization adds an L2 penalty term to the loss function?**\n",
    "\n",
    "- ✅ **Ridge Regression**  \n",
    "- Lasso Regression  \n",
    "- Elastic Net  \n",
    "- None of the above  \n",
    "\n",
    "**Explanation:** Ridge Regression uses an L2 penalty term which adds the square of coefficients to the loss function to reduce overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### 7.  \n",
    "**Which type of regularization is most appropriate for a linear regression model with a large number of independent variables that are all potentially relevant?**\n",
    "\n",
    "- Ridge Regression  \n",
    "- Lasso Regression  \n",
    "- ✅ **Elastic Net**  \n",
    "- None of the above  \n",
    "\n",
    "**Explanation:** Elastic Net combines both L1 and L2 penalties, making it ideal when many predictors are relevant and possibly correlated.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
