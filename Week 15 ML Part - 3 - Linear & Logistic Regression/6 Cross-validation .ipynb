{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8b339b4",
   "metadata": {},
   "source": [
    "\n",
    "# üìò **Cross-Validation**\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **1. Introduction to Cross-Validation**\n",
    "\n",
    "### ‚úÖ **Definition**\n",
    "Cross-validation is a statistical method used in machine learning to assess the effectiveness and **generalization** of a model. It involves splitting the dataset into multiple parts (or \"folds\") and training the model on different subsets while testing it on others. This gives a more reliable measure of a model's performance than a single train-test split.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **2. Why Use Cross-Validation?**\n",
    "\n",
    "| **Purpose**             | **Explanation**                                                                                                                                                          |\n",
    "|-------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| ‚úÖ **Better Model Evaluation**  | Provides a **more accurate** measure of model performance by testing it on multiple subsets of data.                                                                  |\n",
    "| ‚úÖ **Reduces Overfitting**      | Prevents the model from memorizing the training data, ensuring it generalizes better.                                                                                  |\n",
    "| ‚úÖ **Handles Data Scarcity**    | Especially useful when data is scarce, ensuring that every data point gets a chance to be both training and test data.                                                   |\n",
    "| ‚úÖ **Helps with Hyperparameter Tuning** | Aids in choosing the best model configuration (e.g., tree depth, learning rate) by evaluating each parameter combination effectively. |\n",
    "\n",
    "---\n",
    "\n",
    "## üìà **3. Important Concepts Behind Cross-Validation**\n",
    "\n",
    "### 1. **Overfitting**:\n",
    "- **Definition**: The model learns the **training data too well**, including noise and outliers, leading to poor performance on new, unseen data.\n",
    "\n",
    "### 2. **Underfitting**:\n",
    "- **Definition**: The model is too simplistic and fails to capture the underlying patterns in the data, resulting in poor performance even on the training data.\n",
    "\n",
    "### 3. **Bias-Variance Tradeoff**:\n",
    "- **Bias**: High bias occurs when the model is too simple and doesn't capture the underlying patterns (underfitting).\n",
    "- **Variance**: High variance occurs when the model is too complex and fits the training data too closely, capturing noise (overfitting).\n",
    "- **Cross-validation** helps **balance** both bias and variance.\n",
    "\n",
    "### 4. **Hyperparameter Tuning**:\n",
    "- **Definition**: Hyperparameters are the settings used to control the learning process (e.g., depth of decision trees, learning rate in gradient boosting).\n",
    "- **Cross-validation** is a crucial tool for selecting the best combination of hyperparameters to maximize model performance.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ **4. Common Cross-Validation Techniques**\n",
    "\n",
    "### üü¶ **A. K-Fold Cross-Validation (Most Popular)**\n",
    "\n",
    "- **How It Works**:\n",
    "  1. Split the data into **K** equal parts (folds).\n",
    "  2. Train the model on **K-1** folds, and test on the remaining fold.\n",
    "  3. Repeat this for each fold and calculate the **average score**.\n",
    "\n",
    "#### üìå **Example** (k=5):\n",
    "\n",
    "| **Run** | **Train Data**           | **Test Data** |\n",
    "|---------|--------------------------|---------------|\n",
    "| 1       | Fold2 + Fold3 + Fold4 + Fold5 | Fold1        |\n",
    "| 2       | Fold1 + Fold3 + Fold4 + Fold5 | Fold2        |\n",
    "| 3       | Fold1 + Fold2 + Fold4 + Fold5 | Fold3        |\n",
    "| 4       | Fold1 + Fold2 + Fold3 + Fold5 | Fold4        |\n",
    "| 5       | Fold1 + Fold2 + Fold3 + Fold4 | Fold5        |\n",
    "\n",
    "#### üìã **Python Code Example for K-Fold Cross-Validation**:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Initialize model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Define K-Fold CV\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Run CV\n",
    "scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "print(\"Each Fold Score:\", scores)\n",
    "print(\"Average Accuracy:\", np.mean(scores))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üü® **B. Stratified K-Fold Cross-Validation**\n",
    "\n",
    "- **How It Works**:\n",
    "  - Similar to K-Fold, but ensures that each fold has a **representative distribution** of the target classes (e.g., for imbalanced datasets).\n",
    "  - Useful when class distribution is skewed (e.g., fraud detection, rare disease prediction).\n",
    "\n",
    "#### üìã **When to Use**:\n",
    "- **Stratified K-Fold** is preferred when the dataset has **imbalanced classes**.\n",
    "\n",
    "---\n",
    "\n",
    "### üü© **C. Leave-One-Out Cross-Validation (LOOCV)**\n",
    "\n",
    "- **How It Works**:\n",
    "  - Each sample is used as a **test case** exactly once, with the remaining data used for training.\n",
    "  - For a dataset with **N** samples, LOOCV results in **N models** being trained.\n",
    "\n",
    "#### üìã **Advantages**:\n",
    "- Very accurate but computationally expensive.\n",
    "- Best suited for **small datasets** where every data point is valuable.\n",
    "\n",
    "#### üìã **Disadvantages**:\n",
    "- **Time-consuming** and computationally expensive for larger datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### üüß **D. Repeated K-Fold Cross-Validation**\n",
    "\n",
    "- **How It Works**:\n",
    "  - Repeats the **K-Fold cross-validation** multiple times with different random splits.\n",
    "  - Provides a **more robust and stable evaluation** of model performance.\n",
    "\n",
    "#### üìã **When to Use**:\n",
    "- Used in **hyperparameter tuning** to get a better estimate of the model's ability.\n",
    "\n",
    "---\n",
    "\n",
    "### üü• **E. Time Series Cross-Validation (Rolling/Expanding Window)**\n",
    "\n",
    "- **How It Works**:\n",
    "  - Used when **data order matters**, such as time-series data.\n",
    "  - Ensures the model is trained on past data and tested on future data (no data leakage).\n",
    "  - **No shuffling** allowed.\n",
    "\n",
    "#### üìã **When to Use**:\n",
    "- Ideal for tasks like **forecasting** or **stock price prediction**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è **5. Key Terms in Cross-Validation**\n",
    "\n",
    "| **Term**          | **Meaning**                                                                                     |\n",
    "|-------------------|-------------------------------------------------------------------------------------------------|\n",
    "| **Fold**          | A partition of data used in cross-validation (e.g., K-Fold has K partitions).                   |\n",
    "| **Estimator**     | The machine learning algorithm used (e.g., Logistic Regression, Decision Trees).                 |\n",
    "| **Scoring Metric**| Evaluation metric used to assess performance (e.g., accuracy, F1-score).                        |\n",
    "| **Hyperparameter**| Settings that control the learning process (e.g., `max_depth`, `n_estimators` in models).       |\n",
    "| **GridSearchCV**  | Exhaustively searches for the best hyperparameter combinations using cross-validation.          |\n",
    "| **RandomizedSearchCV**| Randomly samples combinations of hyperparameters for faster results than GridSearchCV.      |\n",
    "\n",
    "---\n",
    "\n",
    "## üíª **6. Python Code Examples**\n",
    "\n",
    "#### ‚úÖ **Simple K-Fold Example**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Initialize model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Define K-Fold CV\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Run CV\n",
    "scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "print(\"Each Fold Score:\", scores)\n",
    "print(\"Average Accuracy:\", np.mean(scores))\n",
    "```\n",
    "\n",
    "#### ‚úÖ **GridSearchCV with Cross-Validation**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **7. Pros and Cons**\n",
    "\n",
    "### ‚úÖ **Advantages**:\n",
    "- **Reduces overfitting**\n",
    "- **Makes full use of available data**\n",
    "- **Helps in model tuning**\n",
    "- **Provides stable and reliable performance metrics**\n",
    "\n",
    "### ‚ùå **Disadvantages**:\n",
    "- **Time-consuming**, especially with large datasets.\n",
    "- **Complex for beginners** to understand and implement.\n",
    "- **Not suitable** for certain types of data, such as time series where the order is crucial.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ **8. When to Use Which Cross-Validation Technique**\n",
    "\n",
    "| **Situation**                   | **CV Technique**        |\n",
    "|----------------------------------|-------------------------|\n",
    "| General purpose                  | K-Fold                 |\n",
    "| Imbalanced classes               | Stratified K-Fold      |\n",
    "| Very small dataset               | LOOCV                  |\n",
    "| Time-dependent data (e.g., stock price) | TimeSeriesSplit     |\n",
    "| Need robust evaluation           | Repeated K-Fold        |\n",
    "| Hyperparameter tuning            | K-Fold + GridSearchCV  |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **Quick Revision Summary**\n",
    "\n",
    "| **Term**                     | **Summary**                                                   |\n",
    "|------------------------------|---------------------------------------------------------------|\n",
    "| **Cross-Validation**          | A method for model evaluation using multiple train-test splits |\n",
    "| **K-Fold**                    | Common technique with K training/testing cycles               |\n",
    "| **Stratified K-Fold**         | Ensures balanced target class distribution                    |\n",
    "| **LOOCV**                     | High accuracy, but computationally expensive                  |\n",
    "| **GridSearchCV**              | Tuning hyperparameters via cross-validation                   |\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
