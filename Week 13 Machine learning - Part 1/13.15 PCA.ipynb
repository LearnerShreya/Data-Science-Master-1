{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Principal Component Analysis (PCA)**  \n",
    "**Principal Component Analysis (PCA)** is a **dimensionality reduction** technique that transforms high-dimensional data into a lower-dimensional space while preserving **maximum variance**. It is widely used in **machine learning**, **computer vision**, and **data visualization**.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Standardization**  \n",
    "Since PCA is sensitive to scale, we first **standardize** the dataset to have **zero mean** and **unit variance**:\n",
    "\n",
    "$$\n",
    "X' = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- **X** = original data  \n",
    "- **μ** = mean of each feature  \n",
    "- **σ** = standard deviation of each feature  \n",
    "- **X'** = standardized data  \n",
    "\n",
    "---\n",
    "\n",
    "## **2. Compute the Covariance Matrix**  \n",
    "The **covariance matrix** represents the relationship between features and is computed as:\n",
    "\n",
    "$$\n",
    "C = \\frac{1}{n} X^T X\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- **C** = covariance matrix  \n",
    "- **n** = number of samples  \n",
    "- **X^T** = transpose of the standardized data matrix  \n",
    "\n",
    "---\n",
    "\n",
    "## **3. Compute Eigenvalues & Eigenvectors**  \n",
    "To determine the **principal components**, we solve the eigenvalue problem:\n",
    "\n",
    "$$\n",
    "C v = \\lambda v\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- **λ** = eigenvalues (representing variance explained by each principal component)  \n",
    "- **v** = eigenvectors (representing the direction of principal components)  \n",
    "\n",
    "---\n",
    "\n",
    "## **4. Select Principal Components**  \n",
    "- Sort **eigenvalues** (λ₁, λ₂, ..., λ<sub>d</sub>) in **descending order**.  \n",
    "- Select the **top k** eigenvectors corresponding to the highest eigenvalues.  \n",
    "- The chosen eigenvectors form the **projection matrix V<sub>k</sub>**.  \n",
    "\n",
    "The **explained variance ratio** for the first **k** principal components is:\n",
    "\n",
    "$$\n",
    "\\text{Explained Variance Ratio} = \\frac{\\sum_{i=1}^{k} \\lambda_i}{\\sum_{j=1}^{d} \\lambda_j}\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- **d** = total number of features  \n",
    "\n",
    "---\n",
    "\n",
    "## **5. Transform Data**  \n",
    "The original data is projected onto the new **lower-dimensional space**:\n",
    "\n",
    "$$\n",
    "X_{\\text{new}} = X V_k\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- **X_new** = transformed data in the lower-dimensional space  \n",
    "- **V_k** = matrix of the top **k** eigenvectors  \n",
    "\n",
    "---\n",
    "\n",
    "## **Python Implementation of PCA**  \n",
    "### **Step 1: Standardizing the Data**\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Sample Data\n",
    "X = np.array([[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0]])\n",
    "\n",
    "# Standardizing the Data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "\n",
    "### **Step 2: Compute PCA**\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Applying PCA to reduce to 1 component\n",
    "pca = PCA(n_components=1)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Transformed Data:\\n\", X_pca)\n",
    "```\n",
    "\n",
    "### **Step 3: Explained Variance Ratio**\n",
    "```python\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# **When to Use PCA?**  \n",
    "✔️ When working with **high-dimensional** datasets  \n",
    "✔️ When features are **correlated**, leading to redundancy  \n",
    "✔️ When reducing dimensions helps **avoid overfitting**  \n",
    "✔️ When data needs to be **visualized** in **2D or 3D**  \n",
    "✔️ When reducing computational cost in machine learning models  \n",
    "\n",
    "---\n",
    "\n",
    "# **Limitations of PCA**  \n",
    "❌ PCA assumes **linearity** in data, which may not always be true.  \n",
    "❌ PCA does not work well if features are **not correlated**.  \n",
    "❌ PCA reduces interpretability, making it harder to understand transformed features.  \n",
    "❌ PCA is sensitive to **outliers**, which can distort results.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Sample Data\n",
    "X = np.array([[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0]])\n",
    "\n",
    "# Standardizing the Data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data:\n",
      " [[ 0.5124457 ]\n",
      " [-2.57528445]\n",
      " [ 0.69555387]\n",
      " [-0.1485184 ]\n",
      " [ 1.51580328]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Applying PCA to reduce to 1 component\n",
    "pca = PCA(n_components=1)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Transformed Data:\\n\", X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.96982031]\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
